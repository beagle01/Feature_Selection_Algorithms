{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Feature Selection Methods\n",
    "\n",
    "1. Feature selection: univariate selection. Pearson correlation is only for linear relationship of two variables.\n",
    "\n",
    "2. Mutual information and maximal information coefficient (MIC)\n",
    "\n",
    "3. Model Based Ranking: Linear Regression, Lasso, and Random Forest regressor.  Use coefficient of regression models for selecting and interpreting features.  This approach can work well when the data is not very noisy and the features are independent.  \n",
    "\n",
    "   Regularization is a method for adding additional constraints or penalty to a model with the goal of preventing overfitting and improving generalization. L1 regularization / Lasso (Linear model trained with L1 prior as regularizer) solves the minimization of the least-squares penalty. L2 regularization / Ridge (or Tikhomov regularization) solves a regression model where the loss function is the linear least squares function and regularizaion is given by the L2-norm.\n",
    "   Random forests are among the most popular machine learning methods thanks to their relatively good accuracy, robustness and ease for use. Random forests are popular approaches for feature ranking. They provide two straightforward methods for feature selection: mean decrease impurity and mean decrease accuracy. Mean decrease impurity: Gini impurity or informatio gain/entropy for classification, variance for regression trees. Mean decrease accuracy is used to directly measure the impact of each feature on accuracy of the model, to permute the values of each feature and to measure how much the permutation decreases the accuracy of the model. \n",
    "\n",
    "4. Stability Seletion and Recursive Feature Elimination (RFE). Both can be considered wrapper methods. They build on top of other (model based) selectin methods such as regression or SVM, building models on different subsets of data and extracting the ranking from the aggregates. Stability selection is based on subsampling in combination with selection algorithm (which could be regression, SVMs or other similar method).\n",
    "\n",
    "   Stability selection is useful for both pure feature selection to reduce overfitting and data interpretaton: in general, good features won't get 0 as coefficients because there are similar, correlated features in the dataset.\n",
    "   Recursive feature elimination (RFE) is based on the idea to repeatedly construct a model (for example an SVM or a regression model) and to choose either the best or worst performing feature (for example based on coefficients), setting the feature aside and then repeating the process with the rest of the features.This process is applied until all features in the dataset are exhausted. Features are then ranked according to when they were eliminated. So it is a greedy optimization for finding the best performing subset of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low noise: (0.71824836862138408, 7.3240173129983507e-49)\n",
      "High noise: (0.057964292079338155, 0.31700993885324752)\n"
     ]
    }
   ],
   "source": [
    "# feature selection: univariate selection\n",
    "# Pearson correlation\n",
    "\n",
    "np.random.seed(0)\n",
    "size = 300\n",
    "x = np.random.normal(0, 1, size)\n",
    "print(\"Low noise:\", pearsonr(x, x + np.random.normal(0, 1, size)))\n",
    "print(\"High noise:\", pearsonr(x, x + np.random.normal(0, 10,size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTfUqzwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f35e02174e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, x + np.random.normal(0, 1, size))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCL4gCEJL+P99vHIseKOhdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f35ddf75080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, x + np.random.normal(0, 10, size))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-linear relationship\n",
      "High noise: (0.010361067100016986, 0.85816183565537207)\n"
     ]
    }
   ],
   "source": [
    "# Pearson correlation is only for linear relationship of two variables.\n",
    "\n",
    "x = np.random.uniform(-1,1,size)\n",
    "print(\"non-linear relationship\")\n",
    "print(\"High noise:\", pearsonr(x, x**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X9wHOWd5/H314NMZPJDdnByYbBjwjnehXOwcips1lUX\nlg0xkMJMWIjt2LXJHQeX3c3WGVjV2sEXDDHBiSqQ2wp3u5DL5hJ8YOw1c6Ig55AAlSoKcyg1shWT\ncjAQjIdc8MYWd4sVGOTn/pgepy1N9/RIPTM9PZ9XlQupuzXz0JK+evr7fJ/nMeccIiKSLjNa3QAR\nEYmfgruISAopuIuIpJCCu4hICim4i4ikkIK7iEgKKbiLiKSQgruISAopuIuIpNBprXrjM8880y1Y\nsKBVby8i0pZ+9rOf/ZNzbm6t61oW3BcsWMDQ0FCr3l5EpC2Z2StRrlNaRkQkhRTcRURSSMFdRCSF\nFNxFRFJIwV1EJIUU3EVEUkjBXUQkhWoGdzP7rpm9bmY/DzhvZva3ZnbQzPaZ2cfjb6aIiNQjyiSm\n7wHfBr4fcP5yYKH3bynwX73/Nky+UGRg9wFeGx3jrJ5u+lcsItebbeRbioi0lZo9d+fcT4GjIZdc\nBXzfle0BeszsQ3E1cKJ8oUj/zr0UR8dwQHF0jP6de8kXio16SxGRthNHzj0LvOr7/LB3rCFue2Q/\npXF3yrHSuOO2R/Y36i1FRNpOUwdUzewGMxsys6EjR45M6TWOHS/VdVxEpBPFsXBYEZjn+/xs79gk\nzrl7gXsB+vr6XLVrRETSphXjhHH03AeBP/OqZpYBbzjnfh3D61bV090VeG7tfc806m1FRKYkXyiy\ncdfIKeOEG3eNNHycMEop5APAM8AiMztsZteZ2RfN7IveJY8BLwEHgfuAv2hYa4HNK88PPPf0i0c1\nsCoiiTKw+wBjpfFTjo2VxhnYfaCh71szLeOcW1PjvAP+MrYW1ZDrzbJ++3Dg+YHdB1QWKSKJ8dro\nWF3H49KWM1QzZoHnig2+YSIi9eiZVT2VfFZPd0Pfty2D+5ql8wLPGSg1IyKJsCk/UrWSrytj9K9Y\n1ND3bsvgviW3mOXnzql6zoFq3kWk5fKFItv2HKp67oyZp7VFtUxLbLv+osBzx46X1HsXkZYa2H2A\noHrvN8YaPy+nbYM7QDYkZ9XokWgRkTBh43+NzrdDmwf3sJxVo0eiRUSC5AtFgso+jPDYFZe2Du65\n3mzgpKb3hUx2EhFppM2D+wNTMmuXzW9KuXZbB3coT2rqmjH5b+Sbb7+jvLuINF2+UGQ0JKe+Jbe4\nKe1o++Ce683y7ndNnotVGnfKu4tI04VV64WNE8at7YM7wGjAipDKu4tIM+ULxdAVapuRa69IRXAP\nGnluxoi0iEhFWLZg9qyupi6Nkorg3r9iEd1dmUnH33xLeXcRaZ6w8sdbrwxe9LARUhHcc71Z7rx6\nMbMnrOEwOlbixu3DbMqPtKhlItIpwuJMT3dze+2QkuAO5QA/a+bkgVUH3L/nkHrwItJQQUsNQPhS\n5Y2SmuAO4QOo/TuClwkWEZmusK3lWrEMeaqCe9gAaumEVosUkc6RquBeq8xIde8i0giX3vVU4Lkz\nZk4u9miGVAX3XG82cD0H0EYeIhK/S+96ihdef7PqucwM447PNGdG6kSpCu5QXrchjFIzIhKnoMAO\n8M1rL2jZtp+pC+5hG3mANvIQkfjU6iy2cj/n1AV3qL2Rh4hIHJJchZfK4F6LUjMiMl2b8iOUTgSf\nX/iBM5rXmCpSG9yD1nkH6N+xVwFeRKblgWdfDT3/+E0XN6chAVIb3IPWeQconXBsHlTuXUSmbtwF\nT1uauBRKK0yer58SlYGM9dur58TCFtMXEQlT68m/2YuEVZPanjvUHqlWakZE6pUvFNm4K3iRsOXn\nzmlplUxFqoM7hD8eKTUjIvUa2H2AsdJ41XPrls0PrdZrptQH97DHo9GxknrvIlKXoJnuRvP2R40i\n9cE915sNrZzRpCYRiSpszfak7fyW+uAO4WspHzuu3ruIRBNW/tjM/VGjiBTczewyMztgZgfNbEOV\n8/PN7EkzK5jZPjO7Iv6mTl2uN6vcu4hMW1j5YxIGUf1qBnczywD3AJcD5wFrzOy8CZdtAh5yzvUC\nq4H/EndDp6tW7l1EJEzYE37GwtajbY0oPfcLgYPOuZecc28DDwJXTbjGAe/1Pn4f8Fp8TYxH0v6q\nikh7CdsPYs3SeU1sSTRRgnsW8CeaDnvH/DYD68zsMPAY8FfVXsjMbjCzITMbOnLkyBSaOz1BqZkk\nzCYTkWQL2w8iSVUyFXENqK4BvuecOxu4AviBmU16befcvc65Pudc39y5c2N66+huvfJ8ujKnPj51\nZSwRs8lEJLnCqmSyCauSqYiy/EAR8D9znO0d87sOuAzAOfeMmb0LOBN4PY5GxqWSmhnYfYDXRsc4\nq6eb/hWLlLIRkUD5QpH79xyqes5IXpVMRZTg/hyw0MzOoRzUVwOfm3DNIeBPgO+Z2R8C7wKan3eJ\nINebVTAXkcjCqukcyR3PqxncnXPvmNmXgN1ABviuc26/md0ODDnnBoGbgfvM7EbK/79fcC6kZigh\n8oWievEiEiqsmi6pKRmIuCqkc+4xygOl/mNf8X38PLA83qY1VmXxn8oaEcXRMW7cPszQK0cTOTgi\nIsmT1JQMdMgM1WqqLf7jgG17DmnGqoicFFRNd8bMTKKf9Ds2uL8WUNbkCK9nFZHOkS8UqZZg7soY\nd3wm2U/4HRvcwxb5CatnFZHOUEndTsy5z57VxcA1FyS61w4dHNz7VywiaMKwoY08RDpd0Lrts2ae\nlvjADh0c3HO9WdYum1/1nFIzIhKUug06njQdG9whfMpwcXRMvXeRDpQvFFm+9QmCarmTtm57kI4O\n7hBep7px14gCvEgHqeTZg8bdursyiS5/9Ov44N6/YhHdXZmq58ZK40rPiHSQsP1Rsz3d3Hn14rbI\nt0PESUxpVvlGrd8+XPW8KmdEOkfY/qhPb7ikuY2Zpo7vuUM5wAelZ1Q5I9IZ8oViYAVdu+TZ/RTc\nPUGlkQ5toi3SCQZ2H6g6iJrklR/DKLh7cr3ZwNFxbaItkn5hs9bbJc/up+DuE1Y5o967SHptyo8E\ndu6SvPJjGAV3n7BHL/XeRdJpU34kcDOOdip9nEjB3SfXm6WnO3g/VZVFiqTPA8++GniunUofJ1Jw\nn2DzyuD9VNtl2rGIRDcesq9QuwZ2UHCfJKz33o7lUCLSmRTcq9i88vxJs1bbOfcmItVtyo+0ugkN\n0/EzVKupPIppf1WR9MoXimwLGEiF9q2SqVBwD5DrzSqYi6RY0KSlinZ/UldaRkQ6Uti6UT3dXW3f\nuVNwF5GOE7aOjBFeNdcuFNxFpOPc9sj+wJTM2mXz277XDsq5121TfoQHnn2VcefImLFm6bzQHZ1E\nJFk25Uc4drwUeD4tv88K7nWYOE153LmTn6flB0IkzdJeIeOntEwdgqYph01fFpHk2DwYnI6B9q+Q\n8VNwr0PQNOWw6csikgz5QpHRseB0TBoqZPwU3OuQserj60HHRSQ5whb+S0uFjJ+Cex3WLJ1X13ER\nSY6wuva0VMj4RQruZnaZmR0ws4NmtiHgms+a2fNmtt/M/ke8zUyGLbnFrFs2/2RPPWPGumXzNZgq\nknBhde2zZ3Wl8nfYXI18sZllgF8ClwKHgeeANc65533XLAQeAi5xzh0zsw84514Pe92+vj43NDQ0\n3fa3VL5Q1PozIm1g+dYnqvbcDbh71ZK2+r01s5855/pqXRelFPJC4KBz7iXvhR8ErgKe911zPXCP\nc+4YQK3Angb5QpEbtw+fHHkvjo5x4/ZhoL3XgBZJo7TtjxpFlLRMFvDX+h32jvl9FPiomT1tZnvM\n7LK4GphUf71j76SSKucdF5FkCdqLIU117RPFNYnpNGAhcDFwNvBTM1vsnBv1X2RmNwA3AMyfPz+m\nt26Nd05UT2cFHReR5qukToujYxic0iFL+x4NUXruRcBfDnK2d8zvMDDonCs5516mnKNfOPGFnHP3\nOuf6nHN9c+fOnWqbRURqyheKbNw1cjLX7uDkoGq2p7ut90eNIkrP/TlgoZmdQzmorwY+N+GaPLAG\n+AczO5NymualOBsqIlKPgd0HGCuNn3LMUQ7sT2+4pDWNaqKaPXfn3DvAl4DdwC+Ah5xz+83sdjNb\n6V22G/itmT0PPAn0O+d+26hGJ8HCD5wReG751ifIFyY+3IhIMwUNonbKRveRcu7OuceAxyYc+4rv\nYwfc5P3rCI/fdDGX3vUUL7z+5qRzxdExNu4q782Y5sc+kaTKF4rMMKu6NEinbHSvGarT8PhNF/Or\nrZ+uOuI+VhoPne4sIo1RybVXC+xpH0T1U3CPQac//okkSbVcO5RnlKd9ENVPwT0GQY95nfL4J5Ik\nQZ2qE851TGAHBfdY9K9YRHdXZtLx4ugYS277kQZXRZpIna0yBfcY5Hqz3Hn1YmbP6pp0bnSsxPrt\nwwrwIk1SrbPVSbn2CgX3mOR6s8yaGVx8tHHXvia2RqRzVTpb2Z5ujM6YsFSN9lCNUdgA6ljpRBNb\nItLZcr3ZjgvmE6nnHqNOy+mJSHIpuMcoLKc3QzvxiTREvlBk+dYnOGfDo5od7qPgHqNcb5bl586p\neu5zS9t7FUyRJPIvDub4/exwBXgF99htu/6iU7bim2HQ3TWDbXsOqVchErNqE5Y0O7xMwb0BtuQW\n8+KdV/CtVUs4/bQMY6UTJ3sVN24fZlN+pNVNFGl7+UIxcNNrzQ5XcG+ooCVHt+05pB68yDRU0jFB\nVNyg4N5QYfs26rFRZOo2D+6vun4MdOaEpWoU3BsorPegx0aRqckXioyOlQLPd+KEpWoU3Buof8Ui\ngiog9dgoMjW3PbI/8FzGTIHdo+DeQLneLGuXzZ8U4PXYKDI1+UKRY8eDe+3V1nDvVAruDbYlt5i7\nVy3p+HUuRKYrXyjSv3Nv6DXVNs7pVFpbpgkmrnNRmVH32ugYZ/V0079ikYK9SA23PbKf0nh4z1xP\nxL+n4N5klRKuyki/9lsViSYsHQOwbtl8/Q75KC3TZJpRJxK/b61awpbc4lY3I1EU3JssqASyODqm\niU0iAWr9bqjHPpmCe5OFlUBqwSORyWrNRu3pnrwDmii4N13QfqtQTs+E1fCKdJp8ocjND+0NnI3a\nNcPYvPL8JreqPSi4N1llC7Agx46X1HsX4fc99rDa9YFrL1BKJoCCewvkerOh9bjqvYtULz7wy/Z0\nK7CHUHBvkbB6XPXeRcLXX9Is79oU3Fsk15sNHQjq3zHcxNaIJE9Q8UHGTLO8I1Bwb6GwgaDSCVh7\n3zNNbI1IMuQLRXpv/1HVjTi6uzJ887PKs0eh4N5CtXrvT794tImtEWm9fKHIzTv2Vp2NOntWl3rs\ndYgU3M3sMjM7YGYHzWxDyHV/ambOzPria2K61Srj0pZ80km+vGsf4yeqV8fMmnmaAnsdagZ3M8sA\n9wCXA+cBa8zsvCrXvQf4j8CzcTcyzWr9sN6vLfmkQ+QLRY6XTgSe1wY39YnSc78QOOice8k59zbw\nIHBVleu+Cnwd+F2M7esIy8+dE3pepZHSCWqtr6QNbuoTJbhngVd9nx/2jp1kZh8H5jnnHg17ITO7\nwcyGzGzoyJEjdTc2rbZdfxFdId+JWqvhiaRBtQFUP5U+1mfaA6pmNgO4C7i51rXOuXudc33Oub65\nc+dO961TZeDaJa1ugkjL5AvFwC0pQcv5TkWU4F4E5vk+P9s7VvEe4F8BT5nZr4BlwKAGVeuT680y\nK6D7roWRJO0Gdh8gaJGBdcvmaznfKYgS3J8DFprZOWY2E1gNDFZOOufecM6d6Zxb4JxbAOwBVjrn\nhhrS4hT72tUfo2vGqf0XLYwkabcpPxKaklFgn5qaOzE5594xsy8Bu4EM8F3n3H4zux0Ycs4Nhr+C\nRFV57BzYfUBb8ElHWHvfM6HzObQn6tRF2mbPOfcY8NiEY18JuPbi6Terc03cb7UiXygq6Euq5AvF\n0MCu9WOmR3uotgHtuyppVKv0UbNRp0fLD7QB7bsqaRQ2KSljpsA+TQrubSBosKlWXbBIkoVNSlqz\ndF7gOYlGaZk2kDGruhtNxsIqg0WSaVN+hAeefTVwh6Xl585RhUwMFNzbQNAvQdj2YyJJdOldT/HC\n629WPZdVoUCsFNzbQLanu2oKRmVi0k425UcCA3vGjKc3XNLkFqWbcu5toH/FIrq7MqccU5mYtJsH\nnn018JyeQuOnnnsbCJrcNPTKUW5+aC/jzpExY83SecpVSmKFBXCNH8VPwb1NTJzctCk/wv17Dp38\nfNy5k58rwEuSVCbghVF1TPyUlmlTQY+4YY++Is22KT/CjduHQ8t2F37gDHVIGkDBvU2FVdBo5yZJ\ngnyhyLY9hwJXe8yYsW7ZfB6/6eJmNqtjKC3TpoJq3wEtTSCJsHlwf2BgN+DFO69oZnM6jnrubSos\nRzlWGmf99mFtri0tsyk/wuhY8A5i2jKv8RTc29SW3GLWLZsfes39ew4pwEvT5QvFUwb7JzK0ZV4z\nKLi3sS25xTUnMmmAVZpt82D4hu5rtWVeUyi4t7laPSANsEqzhaVjZs/qUmVMkyi4t7lcb7bmHqv9\nO/cqwEsi3HqltoxsFgX3FNi88nxmhEzwK407bnsk/FFZZDo25Uc4d+NjLNjwaOA1s7pmKB3TRCqF\nTIHKL8yXd+3jeOlE1WuOHQ9+VBaZjlr7oAJ0ZYyvXf2xJrVIQD331Mj1Znn+q5eHXtN7+4+UnpFY\n1doH1SivXjpwzQXqtTeZeu4p09PdFTigdex4ifXbhxl65agGtSQWtdaMeXnrp5vUEplIPfeU2bzy\nfLrCEvCU69/Vg5c4hK0Zo5UeW0vBPWVyvVkGrr2g5nUbd+1rQmskzWpNkNNKj62l4J5Cud5szclN\nY6UTrL3vmSa1SNKmsihYEO2D2noK7ikVZXr30y8e1fIEUrdN+RHWbx8OXBQMYNv1FzWtPVKdgntK\n5XqzNdeeAUJ7XyITTdwkphrt7ZsMCu4pFmVxMQcsuU0lkhJNrbWKtChYcii4p1yUAD86VuLmHVqi\nQMLlC8XQfVANLQqWJAruHWBLbjHLz50Tes34Ccff/KMqaKS6ynZ5Ye5etUSDqAkSKbib2WVmdsDM\nDprZhirnbzKz581sn5n9xMw+HH9TZTq2XX8RZ8zMhF7z1jsn1HuXSSp59rAB1HXqsSdOzeBuZhng\nHuBy4DxgjZmdN+GyAtDnnPsYsBP4RtwNlem74zOL6e4KD/DawUn8lt7xeM0B1HXL5qvHnkBReu4X\nAgedcy85594GHgSu8l/gnHvSOXfc+3QPcHa8zZQ45Hqz3Hl17V9C7eAkAB+79X/xm//3dug12Z5u\nBfaEihLcs4B/iPywdyzIdcAPp9MoaZyoJZJaoqCzbcqP8H/fGg+9RpUxyRbrwmFmtg7oAz4RcP4G\n4AaA+fNrBxhpjC25xbx85J9rLtO6cVe5965cameJsoQvqDIm6aL03IuAf5GIs71jpzCzTwK3ACud\nc29VeyHn3L3OuT7nXN/cuXOn0l6JybbrL2L2rPAdnMZK49zysNIznSRqYFeePfmiBPfngIVmdo6Z\nzQRWA4P+C8ysF/h7yoH99fibKY1w65Xnk6mxguSbb49rDZoOsSk/Eimwf/A9MxXY20DN4O6cewf4\nErAb+AXwkHNuv5ndbmYrvcsGgHcDO8xs2MwGA15OEiTXm+Wb115Qs0Ty6RePKsCn3KV3PVWzKgbg\nvadnePaWS5vQIpkucyEzzhqpr6/PDQ0NteS9ZbJ8ocj6GpNUlp87RwtCpVCU9WJAqZikMLOfOef6\nal2nGaoClHvxtbZW0CqS6ZMvFCMFdi3h234U3OWktRFLJBXg0yFfKNK/Y2/N67pmaAnfdqTgLidF\nWYMGyssEqwa+/W3ctY/SifC07Axg4NolzWmQxErBXU6x7fqLagZ4B9z8kFaRbFeb8iOcs/FRxkon\nQq+bAdy1aolq2duUgrtMEiXAjzvHxl0jCvBtZu19z5QXAatRR7Fu2Xxe2vppBfY2puAuVW27/qKa\nyxSMlcZZv32Y8/7TDxXk20DUOvbZs7o0eJoCCu4SqLLRR60qmuOlE1pNMuFqbWjtd+uV5ze4NdIM\nCu4SaktuMXevWkLGaoV4LTaWZAO7D4Suxw7lhcC0Lnt6xLpwmKRT5Zd9464RxkrhKwXe9NDwKV8j\nrZMvFBnYfYDXRsdqBvZZXTP42tUf0/ctRRTcJZLKL32tWawnXPmaoVeOKm/bQlFnnYJmHqeV0jIS\nWdS14KGcotFAa2tUKmJqqaRhFNjTST13qUulNx4leBwvneBmbwakHvebI0pFjAFn9XTTv2KRvi8p\npuAudduSW0zfh+fQv2NvzRmO4ycctzw8oiDSJA88+2rNa17e+ukmtERaTWkZmZJcb5aBay+oWSYJ\n5TXhl9z2I6VoGihfKLJ86xOM15idFOX7JemgnrtMWaU3ftP2YcInssPoWIn124e55eER7vjMYvXk\nYxJ156ST10ccM5H2p567TEuuN8tdq5Ywqyvaj9Kbb49rwlNM6g3sWo+9s2izDolNPeV3FQo4UxP1\nXmfMWLN0nu5xikTdrENpGYlNJYBs23Oo5qSZikqAUvCJprwG+zA1FnQEINvTzdMbLml8oySRFNwl\nVpVKmtse2c+x46VIX3P/nkM88Oyr6mGGyBeKdd3T7q4M/SsWNbhVkmTKuUvscr1ZCl/5VOQJT1Be\nQvj+PYe0EXcV+UKRjbtGIgf2mRnjzqs1aN3plHOXhsoXinx51z6OR8kjeGbP6uLWK8/v+OBUb28d\ntJRAJ4iac1dwl6aYymBrJy9mVW8lDGhwulNoQFUSpZ5lCyoq68TvGDrUEb3RqTzlVCw/d44Cu5xC\nOXdpmi25xXxr1RKyPd11fd3TLx5NdV18vlCk9/YfsX77cN2Bvae7i2+tWtIRf/ykPkrLSMtMJfUA\n6corb8qP1FU6CuXa9W9+9oKOTFeJcu7SJvKFIjc+NFxzw+ZqZhh8bmn75ZnL1S/7GJtC+qVrhjFw\nrQJ7J1POXdpCJUjdvGMv4zVWmJzohCvn8O/fcyjxvfmpPqX4dc1AgV0iU3CXlqsEq1seHuHNt8O3\n8Qvy9ItHWbDhUSA5pZSVbe6Ko2PTfi1Vwki9FNwlEXK9WXK92WlVjFQcO16if2frNgnJF4psHtzP\n6Fj0+vRqzGBtG6adJBkU3CVRKkEeykHypoeGqTNbA0Bp3DGw+wC53uyklMjMjPGNa6aX3pjKQGgU\nRnlZXgV0ma5IA6pmdhnwn4EM8B3n3NYJ508Hvg/8a+C3wCrn3K/CXlMDqhJFvlDkxu3DUwqiBvzR\nuXOmneue1TUDM5tyyiiq7q4Z3Nmhk7YkuqgDqjXr3M0sA9wDXA6cB6wxs/MmXHYdcMw59y+Bu4Gv\n199kkclyvVle3vpplp87p+6vPaune9qBHcqTqRod2Nctm88vvnq5ArvEJkpa5kLgoHPuJQAzexC4\nCnjed81VwGbv453At83MXKvqLCV1JlbC1Ko+6coY/SsWsX77cKObNi0aKJVGiRLcs4B/193DwNKg\na5xz75jZG8D7gX/yX2RmNwA3AMyfr+2+ZOr8wX7iAKa/WiaJwT3pZZuSDk0dUHXO3QvcC+WcezPf\nW9LLPwg70fIYcu7Tke3ppn/FIqVbpOmiBPciMM/3+dnesWrXHDaz04D3UR5YFWmpbddfFMsEonpo\nYFSSIEpwfw5YaGbnUA7iq4HPTbhmEPg88AxwDfCE8u2SFBNTOPVOlqpVLaM0iyRRzeDu5dC/BOym\nXAr5XefcfjO7HRhyzg0C/w34gZkdBI5S/gMgkjhhKRyRNImUc3fOPQY8NuHYV3wf/w64Nt6miYjI\nVGk9dxGRFFJwFxFJIQV3EZEUUnAXEUkhBXcRkRRScBcRSSEFdxGRFGrZBtlmdgR4ZZovcyYTFidL\niCS2K4ltArWrXmpXfdLYrg875+bWuqhlwT0OZjYUZdH6Zktiu5LYJlC76qV21aeT26W0jIhICim4\ni4ikULsH93tb3YAASWxXEtsEale91K76dGy72jrnLiIi1bV7z11ERKpIdHA3s2vNbL+ZnTCzwJFl\nM7vMzA6Y2UEz2+A7fo6ZPesd325mM2Nq1xwze9zMXvD+O7vKNX9sZsO+f78zs5x37ntm9rLv3JJm\ntcu7btz33oO+4628X0vM7Bnv+73PzFb5zsV6v4J+XnznT/f+/w9692OB79xG7/gBM1sxnXZMoV03\nmdnz3v35iZl92Heu6ve0Se36gpkd8b3/v/ed+7z3fX/BzD7fxDbd7WvPL81s1Heukffqu2b2upn9\nPOC8mdnfeu3eZ2Yf952L91455xL7D/hDYBHwFNAXcE0GeBH4CDAT2Auc5517CFjtffx3wJ/H1K5v\nABu8jzcAX69x/RzKm5jM8j7/HnBNA+5XpHYB/xxwvGX3C/gosND7+Czg10BP3Pcr7OfFd81fAH/n\nfbwa2O59fJ53/enAOd7rZJrYrj/2/Qz9eaVdYd/TJrXrC8C3q3ztHOAl77+zvY9nN6NNE67/K8qb\nDDX0Xnmv/W+AjwM/Dzh/BfBDwIBlwLONuleJ7rk7537hnDtQ47ILgYPOuZecc28DDwJXmZkBlwA7\nvev+O5CLqWlXea8X9XWvAX7onDse0/sHqbddJ7X6fjnnfumce8H7+DXgdaDmRI0pqPrzEtLencCf\nePfnKuBB59xbzrmXgYPe6zWlXc65J30/Q3so72fcaFHuV5AVwOPOuaPOuWPA48BlLWjTGuCBGN63\nJufcTyl35IJcBXzfle0BeszsQzTgXiU6uEeUBV71fX7YO/Z+YNQ5986E43H4oHPu197H/wf4YI3r\nVzP5h+sO77HsbjM7vcntepeZDZnZnkqqiATdLzO7kHKP7EXf4bjuV9DPS9VrvPvxBuX7E+VrG9ku\nv+so9wArqn1Pm9muP/W+PzvNbF6dX9uoNuGlrs4BnvAdbtS9iiKo7bHfq0jb7DWSmf0Y+BdVTt3i\nnPufzW50Eez6AAAC4UlEQVRPRVi7/J8455yZBZYceX+VF1Peg7ZiI+UgN5NySdTfALc3sV0fds4V\nzewjwBNmNkI5gE1ZzPfrB8DnnXMnvMNTvl9pZGbrgD7gE77Dk76nzrkXq79C7B4BHnDOvWVm/4Hy\nU88lTXrvWlYDO51z/t3NW3mvmqblwd0598lpvkQRmOf7/Gzv2G8pP/Kc5vW+Ksen3S4z+42Zfcg5\n92svGL0e8lKfBR52zpV8r13pxb5lZv8A/HUz2+WcK3r/fcnMngJ6gX+kxffLzN4LPEr5D/se32tP\n+X5VEfTzUu2aw2Z2GvA+yj9PUb62ke3CzD5J+Q/mJ5xzb1WOB3xP4whYNdvlnPut79PvUB5jqXzt\nxRO+9qlmtMlnNfCX/gMNvFdRBLU99nuVhrTMc8BCK1d6zKT8zRx05VGKJynnuwE+D8T1JDDovV6U\n152U7/MCXCXPnQOqjqw3ol1mNruS1jCzM4HlwPOtvl/e9+5hyvnInRPOxXm/qv68hLT3GuAJ7/4M\nAqutXE1zDrAQ+N/TaEtd7TKzXuDvgZXOudd9x6t+T5vYrg/5Pl0J/ML7eDfwKa99s4FPceoTbMPa\n5LXrDygPTj7jO9bIexXFIPBnXtXMMuANr/MS/72Ke7Q4zn/AZyjnnt4CfgPs9o6fBTzmu+4K4JeU\n//re4jv+Ecq/fAeBHcDpMbXr/cBPgBeAHwNzvON9wHd81y2g/Bd5xoSvfwIYoRyk7gfe3ax2AX/k\nvfde77/XJeF+AeuAEjDs+7ekEfer2s8L5TTPSu/jd3n//we9+/ER39fe4n3dAeDymH/ea7Xrx97v\nQeX+DNb6njapXXcC+733fxL4A9/X/jvvPh4E/m2z2uR9vhnYOuHrGn2vHqBc6VWiHLuuA74IfNE7\nb8A9XrtH8FUBxn2vNENVRCSF0pCWERGRCRTcRURSSMFdRCSFFNxFRFJIwV1EJIUU3EVEUkjBXUQk\nhRTcRURS6P8D1ge4YAi4mzIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f35ddea2ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, x ** 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutual information and maximal information coefficient (MIC)\n",
    "import numpy as np\n",
    "from minepy import MINE\n",
    "m = MINE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIC: 1.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "x = np.random.uniform(-1, 1, 300)\n",
    "m.compute_score(x, x ** 2)\n",
    "print(\"MIC:\", round(m.mic(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model based ranking\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target', 'data', 'feature_names', 'DESCR']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(list(boston))\n",
    "print(len(boston))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Boston House Prices dataset\\n===========================\\n\\nNotes\\n------\\nData Set Characteristics:  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive\\n    \\n    :Median Value (attribute 14) is usually the target\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttp://archive.ics.uci.edu/ml/datasets/Housing\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n**References**\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston['DESCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston[\"data\"]\n",
    "y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.63800000000000001, 'LSTAT'), (0.5, 'RM'), (0.30299999999999999, 'NOX'), (0.219, 'INDUS'), (0.20000000000000001, 'PTRATIO'), (0.14399999999999999, 'ZN'), (0.13500000000000001, 'TAX'), (0.090999999999999998, 'B'), (0.085999999999999993, 'CRIM'), (0.058999999999999997, 'RAD'), (0.027, 'CHAS'), (0.025000000000000001, 'AGE'), (0.016, 'DIS')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=20, max_depth=4, random_state=0)\n",
    "scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    score = cross_val_score(rf, X[:, i:i+1], y, scoring=\"r2\", cv=ShuffleSplit(n_splits=3, test_size=.3, random_state=0))\n",
    "    scores.append((round(np.mean(score), 3), names[i]))\n",
    "print(sorted(scores, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.504, 'LSTAT'), (0.42799999999999999, 'RM'), (0.158, 'PTRATIO'), (0.152, 'INDUS'), (0.109, 'CRIM'), (0.098000000000000004, 'TAX'), (0.086999999999999994, 'ZN'), (0.085000000000000006, 'B'), (0.084000000000000005, 'AGE'), (0.032000000000000001, 'DIS'), (0.028000000000000001, 'RAD'), (-0.016, 'NOX'), (-0.016, 'CHAS')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso()\n",
    "scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    score = cross_val_score(lasso, X[:, i:i+1], y, scoring=\"r2\", cv=ShuffleSplit(n_splits=3, test_size=.3, random_state=0))\n",
    "    scores.append((round(np.mean(score), 3), names[i]))\n",
    "print(sorted(scores, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.504, 'LSTAT'), (0.44700000000000001, 'RM'), (0.153, 'PTRATIO'), (0.14999999999999999, 'INDUS'), (0.11799999999999999, 'NOX'), (0.109, 'CRIM'), (0.098000000000000004, 'TAX'), (0.086999999999999994, 'ZN'), (0.085000000000000006, 'B'), (0.084000000000000005, 'AGE'), (0.031, 'DIS'), (0.027, 'CHAS'), (0.025000000000000001, 'RAD')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    score = cross_val_score(lr, X[:, i:i+1], y, scoring=\"r2\", cv=ShuffleSplit(n_splits=3, test_size=.3, random_state=0))\n",
    "    scores.append((round(np.mean(score), 3), names[i]))\n",
    "print(sorted(scores, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model: 0.984 * X0 + 1.995 * X1 + -0.041 * X2\n"
     ]
    }
   ],
   "source": [
    "# Using coefficient of regression models for selecting and interpreting features\n",
    "# This approach can work well when the data is not very noisy and the features are independent\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "np.random.seed(0)\n",
    "size = 5000\n",
    "\n",
    "# generate a dataset with three features\n",
    "# purely linear relationship between features and the response variable, and no correlatons between features\n",
    "X = np.random.normal(0, 1, (size, 3))\n",
    "# y = X0 + 2*X1 + noise\n",
    "y = X[:, 0] + 2 * X[:, 1] + np.random.normal(0, 2, size)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "# function for pretty-printing linear models\n",
    "def pretty_print_linear(coefs, names=None, sort=False):\n",
    "    if names == None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst, key = lambda x: -np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name) for coef, name in lst)\n",
    "\n",
    "print(\"Linear model:\", pretty_print_linear(lr.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model: -1.291 * X0 + 1.591 * X1 + 2.747 * X2\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "size = 100\n",
    "np.random.seed(5)\n",
    "\n",
    "X_seed = np.random.normal(0, 1, size)\n",
    "x1 = X_seed + np.random.normal(0, .1, size)\n",
    "x2 = X_seed + np.random.normal(0, .1, size)\n",
    "x3 = X_seed + np.random.normal(0, .1, size)\n",
    "\n",
    "y = x1 + x2 + x3 + np.random.normal(0, 1, size)\n",
    "X = np.array([x1, x2, x3]).T\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "print(\"Linear model:\", pretty_print_linear(lr.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso model: -3.707 * LSTAT + 2.992 * RM + -1.757 * PTRATIO + -1.081 * DIS + -0.7 * NOX + 0.631 * B + 0.54 * CHAS + -0.236 * CRIM + 0.081 * ZN + -0.0 * INDUS + -0.0 * AGE + 0.0 * RAD + -0.0 * TAX\n"
     ]
    }
   ],
   "source": [
    "# Regularization is a method for adding additional constraints or penalty to a model\n",
    "# with the goal of preventing overfitting and improving generalization.\n",
    "\n",
    "# L1 regularization / Lasso\n",
    "# Linear model trained with L1 prior as regularizer (aka Lasso)\n",
    "# Lasso estimate solves the minimization of the least-squares penalty\n",
    "# with \\alpha ||w||_1 added, where \\alpha is a constant and ||w||_1 is the \\ell_1-norm of the parameter vector.\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "def pretty_print_linear(coefs, names):\n",
    "    lst = sorted(zip(coefs, names), key=lambda x: -np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name) for coef, name in lst)\n",
    "\n",
    "boston = load_boston()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(boston[\"data\"])\n",
    "# X = boston[\"data\"]\n",
    "y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "\n",
    "lasso = Lasso(alpha=0.3)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "print(\"Lasso model:\", pretty_print_linear(lasso.coef_, names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso model: 3.698 * RM + -2.375 * NOX + 1.953 * CHAS + -1.248 * DIS + -0.798 * PTRATIO + -0.56 * LSTAT + 0.279 * RAD + -0.1 * CRIM + 0.05 * ZN + -0.043 * INDUS + -0.014 * TAX + -0.011 * AGE + 0.01 * B\n"
     ]
    }
   ],
   "source": [
    "# L2 regularization / Ridge\n",
    "# Ridge regression (or Tikhomov regularization) solves a regression model\n",
    "# where the loss function is the linear least squares function and\n",
    "# and regularizaion is given by the L2-norm. \n",
    "# sklearn.linear_model.Ridge has built-in support for multi-variate regression.\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "def pretty_print_linear(coefs, names):\n",
    "    lst = sorted(zip(coefs, names), key=lambda x: -np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name) for coef, name in lst)\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston[\"data\"]\n",
    "y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "\n",
    "ridge = Ridge(alpha=10)\n",
    "ridge.fit(X, y)\n",
    "\n",
    "print(\"Lasso model:\", pretty_print_linear(ridge.coef_, names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed is 0\n",
      "Linear model: 0.728 * X0 + 2.309 * X1 + -0.082 * X2\n",
      "Ridge model: 0.938 * X0 + 1.059 * X1 + 0.877 * X2\n",
      "\n",
      "Random seed is 1\n",
      "Linear model: 1.152 * X0 + 2.366 * X1 + -0.599 * X2\n",
      "Ridge model: 0.984 * X0 + 1.068 * X1 + 0.759 * X2\n",
      "\n",
      "Random seed is 2\n",
      "Linear model: 0.697 * X0 + 0.322 * X1 + 2.086 * X2\n",
      "Ridge model: 0.972 * X0 + 0.943 * X1 + 1.085 * X2\n",
      "\n",
      "Random seed is 3\n",
      "Linear model: 0.287 * X0 + 1.254 * X1 + 1.491 * X2\n",
      "Ridge model: 0.919 * X0 + 1.005 * X1 + 1.033 * X2\n",
      "\n",
      "Random seed is 4\n",
      "Linear model: 0.187 * X0 + 0.772 * X1 + 2.189 * X2\n",
      "Ridge model: 0.964 * X0 + 0.982 * X1 + 1.098 * X2\n",
      "\n",
      "Random seed is 5\n",
      "Linear model: -1.291 * X0 + 1.591 * X1 + 2.747 * X2\n",
      "Ridge model: 0.758 * X0 + 1.011 * X1 + 1.139 * X2\n",
      "\n",
      "Random seed is 6\n",
      "Linear model: 1.199 * X0 + -0.031 * X1 + 1.915 * X2\n",
      "Ridge model: 1.016 * X0 + 0.89 * X1 + 1.091 * X2\n",
      "\n",
      "Random seed is 7\n",
      "Linear model: 1.474 * X0 + 1.762 * X1 + -0.151 * X2\n",
      "Ridge model: 1.018 * X0 + 1.039 * X1 + 0.901 * X2\n",
      "\n",
      "Random seed is 8\n",
      "Linear model: 0.084 * X0 + 1.88 * X1 + 1.107 * X2\n",
      "Ridge model: 0.907 * X0 + 1.071 * X1 + 1.008 * X2\n",
      "\n",
      "Random seed is 9\n",
      "Linear model: 0.714 * X0 + 0.776 * X1 + 1.364 * X2\n",
      "Ridge model: 0.896 * X0 + 0.903 * X1 + 0.98 * X2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "def pretty_print_linear(coefs, names=None, sort=False):\n",
    "    if names == None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst, key = lambda x: -np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name) for coef, name in lst)\n",
    "\n",
    "size = 100\n",
    "# to run the method 10 times with different random seeds\n",
    "for i in range(10):\n",
    "    print(\"Random seed is %s\" % i)\n",
    "    np.random.seed(seed=i)\n",
    "    X_seed = np.random.normal(0, 1, size)\n",
    "    x1 = X_seed + np.random.normal(0, 0.1, size)\n",
    "    x2 = X_seed + np.random.normal(0, 0.1, size)\n",
    "    x3 = X_seed + np.random.normal(0, 0.1, size)\n",
    "    y = x1 + x2 + x3 + np.random.normal(0, 1, size)\n",
    "    X = np.array([x1, x2, x3]).T\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "    print(\"Linear model:\", pretty_print_linear(lr.coef_))\n",
    "    \n",
    "    ridge = Ridge(alpha=10)\n",
    "    ridge.fit(X, y)\n",
    "    print(\"Ridge model:\", pretty_print_linear(ridge.coef_))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients can vary widely for linear regression, depending on the generated data. For L2 regularized model however, the coefficients are quite stable and closely reflect how the data was generated (all coefficients are close to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.4128, 'RM'), (0.38140000000000002, 'LSTAT'), (0.0877, 'DIS'), (0.031600000000000003, 'CRIM'), (0.021399999999999999, 'NOX'), (0.0212, 'PTRATIO'), (0.0117, 'AGE'), (0.010699999999999999, 'B'), (0.0097999999999999997, 'TAX'), (0.0071000000000000004, 'INDUS'), (0.0028, 'RAD'), (0.001, 'ZN'), (0.00080000000000000004, 'CHAS')]\n"
     ]
    }
   ],
   "source": [
    "# Random forests are among the most popular machine learning methods thanks\n",
    "# to their relatively good accuracy, robustness and ease for use.\n",
    "# Random forests are popular approaches for feature ranking.They provide two\n",
    "# straightforward methods for feature selection: mean decrease impurity\n",
    "# and mean decrease accuracy.\n",
    "\n",
    "# Mean decrease impurity\n",
    "# For classification: Gini impurity or informatio gain/entropy\n",
    "# For regression trees: variance\n",
    "\n",
    "# The feature importance measure exposed in sklearn's Random Forest implementations:\n",
    "# sklearn.ensemble.RandomForestRegressor\n",
    "# sklearn.ensemble.RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston[\"data\"]\n",
    "y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for x0, x1, x2:\n",
      "[0.27200000000000002, 0.54800000000000004, 0.17899999999999999]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "size = 10000\n",
    "np.random.seed(seed=10)\n",
    "X_seed = np.random.normal(0, 1, size)\n",
    "x0 = X_seed + np.random.normal(0, 0.1, size)\n",
    "x1 = X_seed + np.random.normal(0, 0.1, size)\n",
    "x2 = X_seed + np.random.normal(0, 0.1, size)\n",
    "X = np.array([x0, x1, x2]).T\n",
    "y = x0 + x1 + x2\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=20, max_features=2)\n",
    "rf.fit(X, y)\n",
    "print(\"Score for x0, x1, x2:\")\n",
    "print(list(map(lambda x: round(x, 3), rf.feature_importances_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.79449999999999998, 'LSTAT'), (0.54390000000000005, 'RM'), (0.087999999999999995, 'DIS'), (0.046199999999999998, 'NOX'), (0.041599999999999998, 'CRIM'), (0.0207, 'PTRATIO'), (0.0149, 'TAX'), (0.012800000000000001, 'AGE'), (0.0057999999999999996, 'B'), (0.0051000000000000004, 'INDUS'), (0.0041000000000000003, 'RAD'), (0.00020000000000000001, 'CHAS'), (0.0001, 'ZN')]\n"
     ]
    }
   ],
   "source": [
    "# Mean decrease accuracy\n",
    "# to directly measure the impact of each feature on accuracy of the model\n",
    "# to permute the values of each feature and measure how much the permutation\n",
    "# decreases the accuracy of the model\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston[\"data\"]\n",
    "y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "scores = defaultdict(list)\n",
    "\n",
    "# cross validate the scores on a number of different random splits of the data\n",
    "rs = ShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n",
    "for train_idx, test_idx in rs.split(np.arange(len(X))):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    rf.fit(X_train, y_train)\n",
    "    acc = r2_score(y_test, rf.predict(X_test))\n",
    "    for i in range(X.shape[1]):\n",
    "        X_t = X_test.copy()\n",
    "        np.random.shuffle(X_t[:, i])\n",
    "        shuff_acc = r2_score(y_test, rf.predict(X_t))\n",
    "        scores[names[i]].append((acc-shuff_acc)/acc)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted([(round(np.mean(score), 4), feat) for feat, score in scores.items()], reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, LSTAT and RM are two features that strongly impact model performance: permuting them decrease model performance by ~79% and ~54%, respectively. Keep in mind that these measurements are made only after the model has been trained (and is depending) on all of the features. This dosen't mean that if we train the model without one of these features, the model performance will drop by that amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:57: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(1.0, 'RM'), (1.0, 'PTRATIO'), (1.0, 'LSTAT'), (0.625, 'B'), (0.60499999999999998, 'CHAS'), (0.42999999999999999, 'CRIM'), (0.38500000000000001, 'TAX'), (0.245, 'DIS'), (0.215, 'NOX'), (0.105, 'INDUS'), (0.059999999999999998, 'ZN'), (0.044999999999999998, 'RAD'), (0.02, 'AGE')]\n"
     ]
    }
   ],
   "source": [
    "# Stability seletion and recursive feature elimination (RFE)\n",
    "# Both can be considered wrapper methods. They build on top of other (model\n",
    "# based) selectin methods such as regression or SVM, building models on\n",
    "# different subsets of data and extracting the ranking from the aggregates.\n",
    "\n",
    "# Stability selection is based on subsampling in combination with selection\n",
    "# algorithm (which could be regression, SVMs or other similar method).\n",
    "# sklearn.linear_model.RandomizedLasso\n",
    "# sklearn.linear_model.RandomizedLogisticRegression\n",
    "\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston[\"data\"]\n",
    "y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "\n",
    "rlasso = RandomizedLasso(alpha=0.025)\n",
    "rlasso.fit(X, y)\n",
    "\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rlasso.scores_), names), reverse=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their rank:\n",
      "[(1, 'NOX'), (2, 'RM'), (3, 'CHAS'), (4, 'PTRATIO'), (5, 'DIS'), (6, 'LSTAT'), (7, 'RAD'), (8, 'CRIM'), (9, 'INDUS'), (10, 'ZN'), (11, 'TAX'), (12, 'B'), (13, 'AGE')]\n"
     ]
    }
   ],
   "source": [
    "# Stability selection is useful for both pure feature selection to reduce\n",
    "# overfitting and data interpretaton: in general, good features won't get\n",
    "# 0 as coefficients because there are similar, correlated features in\n",
    "# the dataset.\n",
    "\n",
    "# Recursive feature elimination (RFE) is based on the idea to repeatedly\n",
    "# construct a model (for example an SVM or a regression model) and to choose\n",
    "# either the best or worst performing feature (for example based on coefficients),\n",
    "# setting the feature aside and then repeating the process with the rest\n",
    "# of the features.This process is applied until all features in the dataset\n",
    "# are exhausted. Features are then ranked according to when they were \n",
    "# eliminated. So it is a greedy optimization for finding the best performing\n",
    "# subset of features.\n",
    "# sklearn.feature_selection.RFE\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston[\"data\"]\n",
    "y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]\n",
    "\n",
    "lr = LinearRegression()\n",
    "# rank all features, i.e. continue the elimination until the last one\n",
    "rfe = RFE(lr, n_features_to_select=1)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "print(\"Features sorted by their rank:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:57: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCorr.\tLasso\tLinearR\tMIC\tRF\tRFE\tRidge\tStabil\tMean\n",
      "x1\t0.3\t0.79\t1.0\t0.39\t0.55\t1.0\t0.77\t0.77\t0.7\n",
      "x2\t0.44\t0.83\t0.56\t0.61\t0.67\t1.0\t0.75\t0.72\t0.7\n",
      "x3\t0.0\t0.0\t0.5\t0.34\t0.13\t1.0\t0.05\t0.0\t0.25\n",
      "x4\t1.0\t1.0\t0.57\t1.0\t0.56\t1.0\t1.0\t1.0\t0.89\n",
      "x5\t0.1\t0.51\t0.27\t0.2\t0.29\t0.78\t0.88\t0.55\t0.45\n",
      "x6\t0.0\t0.0\t0.02\t0.0\t0.01\t0.44\t0.05\t0.0\t0.06\n",
      "x7\t0.01\t0.0\t0.0\t0.07\t0.02\t0.0\t0.01\t0.0\t0.01\n",
      "x8\t0.02\t0.0\t0.03\t0.05\t0.01\t0.56\t0.09\t0.0\t0.1\n",
      "x9\t0.01\t0.0\t0.0\t0.09\t0.01\t0.11\t0.0\t0.0\t0.03\n",
      "x10\t0.0\t0.0\t0.01\t0.04\t0.0\t0.33\t0.01\t0.0\t0.05\n",
      "x11\t0.29\t0.0\t0.6\t0.43\t0.39\t1.0\t0.59\t0.37\t0.46\n",
      "x12\t0.44\t0.0\t0.14\t0.71\t0.35\t0.67\t0.68\t0.47\t0.43\n",
      "x13\t0.0\t0.0\t0.48\t0.23\t0.07\t0.89\t0.02\t0.0\t0.21\n",
      "x14\t0.99\t0.16\t0.0\t1.0\t1.0\t0.22\t0.95\t0.62\t0.62\n"
     ]
    }
   ],
   "source": [
    "# Running the feature selection methods side by side\n",
    "# The dataset: Friedman #1 regression dataset (from Friedman's Multivariate\n",
    "# Adaptive Regression Splines paper).\n",
    "# The data is generated according to the formula:\n",
    "# y=10*sin(pi*x1*x2)+20*(x3-0.5)**2+10*x4+5*x5+\n",
    "# where the x1 to x5 are drawn from uniform distribution and  is the standard\n",
    "# normal deviate N(0,1).\n",
    "# Additionally the original dataset had five noise variables x6 to x10,\n",
    "# independent of the response variable. Here four more variables x11 to x14\n",
    "# are added. Each of the four is very strongly correlated with x1 to x4, respectively,\n",
    "# generated by f(x)=x+N(0,0.01). This yields a correlation coefficient of \n",
    "# more than 0.999 between the variables.\n",
    "# The analysis will illustrate how different feature ranking methods deal\n",
    "# with correlations in the data.\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RandomizedLasso\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from minepy import MINE\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "size = 750\n",
    "X = np.random.uniform(0, 1, (size, 14))\n",
    "\n",
    "# Friedman #1 regression problem\n",
    "y = (10*np.sin(np.pi*X[:, 0]*X[:, 1]) + 20*(X[:, 2]-0.5)**2+10*X[:, 3]+5*X[:, 4] + np.random.normal(0, 1))\n",
    "\n",
    "# Add 3 addtional correlated variable (correlated with X1 - X3)\n",
    "X[:, 10:] = X[:, :4] + np.random.normal(0, 0.025, (size, 4))\n",
    "\n",
    "names = [\"x%s\" % i for i in range(1, 15)]\n",
    "\n",
    "ranks = {}\n",
    "\n",
    "def rank_to_dict(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x, 2), ranks)\n",
    "    return dict(zip(names, ranks))\n",
    "\n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(X, y)\n",
    "ranks[\"LinearR\"] = rank_to_dict(np.abs(lr.coef_), names)\n",
    "\n",
    "ridge = Ridge(alpha=7)\n",
    "ridge.fit(X, y)\n",
    "ranks[\"Ridge\"] = rank_to_dict(np.abs(ridge.coef_), names)\n",
    "\n",
    "lasso = Lasso(alpha=0.05)\n",
    "lasso.fit(X, y)\n",
    "ranks[\"Lasso\"] = rank_to_dict(np.abs(lasso.coef_), names)\n",
    "\n",
    "rlasso = RandomizedLasso(alpha=0.04)\n",
    "rlasso.fit(X, y)\n",
    "ranks[\"Stabil\"] = rank_to_dict(np.abs(rlasso.scores_), names)\n",
    "\n",
    "# stop the search when 5 features are left (they will get equal scores)\n",
    "rfe = RFE(lr, n_features_to_select=5)\n",
    "rfe.fit(X, y)\n",
    "ranks[\"RFE\"] = rank_to_dict(rfe.ranking_, names, order=-1)\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "ranks[\"RF\"] = rank_to_dict(rf.feature_importances_, names)\n",
    "\n",
    "f, pval = f_regression(X, y, center=True)\n",
    "ranks[\"Corr.\"] = rank_to_dict(f, names)\n",
    "\n",
    "mine = MINE()\n",
    "mic_scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    mine.compute_score(X[:, i], y)\n",
    "    m = mine.mic()\n",
    "    mic_scores.append(m)\n",
    "ranks[\"MIC\"] = rank_to_dict(mic_scores, names)\n",
    "\n",
    "r = {}\n",
    "for name in names:\n",
    "    r[name] = round(np.mean([ranks[method][name] for method in ranks.keys()]), 2)\n",
    "    \n",
    "methods = sorted(ranks.keys())\n",
    "ranks[\"Mean\"] = r\n",
    "methods.append(\"Mean\")\n",
    "\n",
    "print(\"\\t%s\" % \"\\t\".join(methods))\n",
    "for name in names:\n",
    "    print(\"%s\\t%s\" % (name, \"\\t\".join(map(str, [ranks[method][name] for method in methods]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With linear correlation (Corr.), each feature is evaluated independently, so the scores for features x1 to x4 are very similar to x11 to x14, while the noise features x5 to x10 are correctly identified to have almost no relation with the response variable.It's not able to identify any relationship between x3 and the response variable since the relationship is quadratic (in fact, this applies almost to all other methods except MIC). This method is not optimal for selecting the top performing features for improving the generalization of a model since all top performing features would essentially be picked twice.\n",
    "\n",
    "Lasso picks out the top performing features while forcing other features to be close to zero. It is clearly useful when reducing the number of features is required, but not necessarily for data interpretation (since it might lead one to believe that features x11 to x13 do not have a strong relationship with the reponse variable.)\n",
    "\n",
    "MIC is similar to correlation coefficient in treating all features \"equally\", additionally it is able to find the non-linear relationship between x3 and the response variable.\n",
    "\n",
    "Random forest's impurity based ranking is typically aggressive in the sense that there is a sharp drop-off of scores after the first few top ones. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Features ordered by impurity decrease:\n",
      "[(0.1084, 'BMXLEG'), (0.0935, 'BMXHT'), (0.091800000000000007, 'BMXWAIST'), (0.091399999999999995, 'BMXTHICR'), (0.084099999999999994, 'BMXCALF'), (0.080100000000000005, 'BMXSUB'), (0.076499999999999999, 'BMXTRI'), (0.0746, 'RIDAGEYR'), (0.073400000000000007, 'BMXARMC'), (0.0722, 'BMXBMI'), (0.067299999999999999, 'BMXWT'), (0.066600000000000006, 'BMXARML'), (0.0201, 'RIAGENDR')]\n",
      "Features sorted by accuracy decrease:\n",
      "[(0.078600000000000003, 'BMXWAIST'), (0.074499999999999997, 'BMXTHICR'), (0.073599999999999999, 'BMXHT'), (0.067199999999999996, 'BMXLEG'), (0.049000000000000002, 'BMXCALF'), (0.047, 'RIDAGEYR'), (0.0436, 'BMXBMI'), (0.031699999999999999, 'RIAGENDR'), (0.023199999999999998, 'BMXSUB'), (0.019199999999999998, 'BMXTRI'), (0.0184, 'BMXARMC'), (0.0178, 'BMXWT'), (0.0060000000000000001, 'BMXARML')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# load a dataset\n",
    "data = pd.read_table(r'NHANES-ICRSR25504-0013-Data.tsv', low_memory=False)\n",
    "\n",
    "# generate a new DataFrame for young males by selecting RIDAGEYR between 18 and 30\n",
    "# excluding RIDRETH1 2 (Other hispanic) and 5 (Other races)\n",
    "sub = data[(data['RIDAGEYR'] >= 18) & (data['RIDAGEYR'] <= 60) & (data['RIDRETH1'] != 2) & (data['RIDRETH1'] != 5)]\n",
    "\n",
    "# generate a new DataFrame for young adults with only body measurements\n",
    "response_var = ['RIDRETH1']\n",
    "explanatory_var = ['BMXWT', 'BMXHT', 'BMXBMI', 'BMXLEG', 'BMXCALF','BMXARML', 'BMXARMC', 'BMXWAIST', 'BMXTRI', \n",
    "                   'BMXSUB', 'BMXTHICR', 'RIAGENDR', 'RIDAGEYR']\n",
    "sub1 = sub[explanatory_var + response_var]\n",
    "\n",
    "for colname in explanatory_var:\n",
    "    sub1[colname] = pd.to_numeric(sub1[colname], errors='coerce')\n",
    "\n",
    "sub1 = sub1.dropna()\n",
    "    \n",
    "# replacing values\n",
    "# sub1['RIDRETH1'].replace(to_replace=[1, 3, 4], value=['Mexican_American', 'White_American', 'Black_American'], inplace=True)\n",
    "\n",
    "array = sub1.values\n",
    "X = array[1:,0:13]\n",
    "y = array[1:,13]\n",
    "names = explanatory_var\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "print(\"Random Forest Classifier\")\n",
    "\n",
    "rfc.fit(X, y)\n",
    "print(\"Features ordered by impurity decrease:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rfc.feature_importances_), names), reverse=True))\n",
    "print()\n",
    "scores = defaultdict(list)\n",
    "\n",
    "# cross validate the scores on a number of different random splits of the data\n",
    "rs = ShuffleSplit(n_splits=20, test_size=0.3, random_state=10)\n",
    "for train_idx, test_idx in rs.split(np.arange(len(X))):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    rfc.fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_test, rfc.predict(X_test))\n",
    "    for i in range(X.shape[1]):\n",
    "        X_t = X_test.copy()\n",
    "        np.random.shuffle(X_t[:, i])\n",
    "        shuff_acc = accuracy_score(y_test, rfc.predict(X_t))\n",
    "        scores[names[i]].append((acc-shuff_acc)/acc)\n",
    "print(\"Features sorted by accuracy decrease:\")\n",
    "print(sorted([(round(np.mean(score), 4), feat) for feat, score in scores.items()], reverse=True))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************\n",
      "Random Forest Classification\n",
      "----------------------------\n",
      "Features sorted by impurity decrease:\n",
      "[(0.14699999999999999, 'mean concave points'), (0.121, 'area error'), (0.11169999999999999, 'worst radius'), (0.1062, 'worst perimeter'), (0.1032, 'worst concave points'), (0.081100000000000005, 'mean concavity'), (0.070499999999999993, 'mean area'), (0.045699999999999998, 'radius error'), (0.040399999999999998, 'worst area'), (0.028299999999999999, 'mean perimeter'), (0.016199999999999999, 'worst texture'), (0.015900000000000001, 'worst fractal dimension'), (0.0147, 'worst concavity'), (0.0134, 'worst smoothness'), (0.011900000000000001, 'mean texture'), (0.0118, 'worst compactness'), (0.01, 'mean smoothness'), (0.0091000000000000004, 'worst symmetry'), (0.0061000000000000004, 'perimeter error'), (0.0054999999999999997, 'mean radius'), (0.0051000000000000004, 'fractal dimension error'), (0.0050000000000000001, 'concavity error'), (0.0030999999999999999, 'smoothness error'), (0.0030000000000000001, 'texture error'), (0.0030000000000000001, 'mean symmetry'), (0.0025999999999999999, 'symmetry error'), (0.0025000000000000001, 'concave points error'), (0.0020999999999999999, 'mean fractal dimension'), (0.002, 'mean compactness'), (0.002, 'compactness error')]\n",
      "----------------------------\n",
      "Accuracy Score:\n",
      "0.9532\n",
      "----------------------------\n",
      "Features sorded by accuracy decrease:\n",
      "[(0.0178, 'worst concave points'), (0.0083999999999999995, 'worst radius'), (0.0067999999999999996, 'worst texture'), (0.0054999999999999997, 'mean concavity'), (0.0041999999999999997, 'area error'), (0.0040000000000000001, 'fractal dimension error'), (0.0038999999999999998, 'worst area'), (0.0033999999999999998, 'mean texture'), (0.0033, 'worst perimeter'), (0.0033, 'worst concavity'), (0.0027000000000000001, 'mean area'), (0.0023999999999999998, 'mean perimeter'), (0.0020999999999999999, 'worst fractal dimension'), (0.0020999999999999999, 'mean concave points'), (0.0018, 'worst symmetry'), (0.0018, 'concave points error'), (0.0015, 'worst smoothness'), (0.0015, 'mean smoothness'), (0.00089999999999999998, 'texture error'), (0.00059999999999999995, 'symmetry error'), (0.00059999999999999995, 'mean symmetry'), (0.0, 'perimeter error'), (0.0, 'mean fractal dimension'), (-0.0001, 'mean radius'), (-0.00029999999999999997, 'smoothness error'), (-0.00059999999999999995, 'compactness error'), (-0.00089999999999999998, 'worst compactness'), (-0.00089999999999999998, 'mean compactness'), (-0.0011999999999999999, 'concavity error'), (-0.0012999999999999999, 'radius error')]\n",
      "****************************\n",
      "****************************\n",
      "Support Vector Classification\n",
      "----------------------------\n",
      "Accuracy Score:\n",
      "0.9474\n",
      "----------------------------\n",
      "Features sorded by accuracy decrease:\n",
      "[(0.20419999999999999, 'mean perimeter'), (0.1943, 'worst area'), (0.1673, 'worst perimeter'), (0.12479999999999999, 'area error'), (0.089599999999999999, 'worst texture'), (0.066799999999999998, 'mean radius'), (0.064000000000000001, 'mean area'), (0.0441, 'worst radius'), (0.011299999999999999, 'texture error'), (0.0079000000000000008, 'worst concavity'), (0.0030000000000000001, 'perimeter error'), (0.0030000000000000001, 'mean texture'), (0.00089999999999999998, 'worst symmetry'), (0.00059999999999999995, 'worst concave points'), (0.00029999999999999997, 'worst compactness'), (-0.0, 'worst smoothness'), (0.0, 'worst fractal dimension'), (0.0, 'symmetry error'), (0.0, 'smoothness error'), (0.0, 'mean symmetry'), (0.0, 'mean fractal dimension'), (0.0, 'fractal dimension error'), (0.0, 'concavity error'), (0.0, 'concave points error'), (0.0, 'compactness error'), (-0.00029999999999999997, 'mean smoothness'), (-0.00029999999999999997, 'mean concavity'), (-0.00029999999999999997, 'mean concave points'), (-0.00029999999999999997, 'mean compactness'), (-0.00059999999999999995, 'radius error')]\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge, RandomizedLasso\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "def pretty_print_linear(coefs, names):\n",
    "    lst = sorted(zip(coefs, names), key=lambda x: -np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name) for coef, name in lst)\n",
    "\n",
    "# load dataset\n",
    "bc = load_breast_cancer()\n",
    "\n",
    "X = bc[\"data\"]\n",
    "y = bc[\"target\"]\n",
    "names = bc[\"feature_names\"]\n",
    "\n",
    "rfc = RandomForestClassifier(random_state = 0)\n",
    "print(\"****************************\")\n",
    "print(\"Random Forest Classification\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "rfc.fit(X, y)\n",
    "print(\"Features sorted by impurity decrease:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rfc.feature_importances_), names), reverse=True))\n",
    "print(\"----------------------------\")\n",
    "\n",
    "rs = ShuffleSplit(n_splits=20, test_size=0.3, random_state=0)\n",
    "scores = defaultdict(list)\n",
    "for train_idx, test_idx in rs.split(np.arange(len(X))):\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "    rfc.fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_test, rfc.predict(X_test))\n",
    "    for i in range(X.shape[1]):\n",
    "        X_t = X_test.copy()\n",
    "        np.random.shuffle(X_t[:, i])\n",
    "        acc_shuffle = accuracy_score(y_test, rfc.predict(X_t))\n",
    "        acc_dec = (acc - acc_shuffle)/acc\n",
    "        scores[names[i]].append(acc_dec)\n",
    "print(\"Accuracy Score:\")\n",
    "print(round(np.mean(acc), 4))\n",
    "print(\"----------------------------\")\n",
    "print(\"Features sorded by accuracy decrease:\")\n",
    "print(sorted([(round(np.mean(score), 4), feature) for feature, score in scores.items()], reverse=True))\n",
    "print(\"****************************\")\n",
    "\n",
    "svc = SVC(kernel=\"linear\", random_state=0)\n",
    "print(\"****************************\")\n",
    "print(\"Support Vector Classification\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "rs = ShuffleSplit(n_splits=20, test_size=0.3, random_state=0)\n",
    "scores = defaultdict(list)\n",
    "for train_idx, test_idx in rs.split(np.arange(len(X))):\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "    svc.fit(X_train, y_train)\n",
    "    acc = accuracy_score(y_test, svc.predict(X_test))\n",
    "    for i in range(X.shape[1]):\n",
    "        X_t = X_test.copy()\n",
    "        np.random.shuffle(X_t[:, i])\n",
    "        acc_shuffle = accuracy_score(y_test, svc.predict(X_t))\n",
    "        acc_dec = (acc - acc_shuffle)/acc\n",
    "        scores[names[i]].append(acc_dec)\n",
    "print(\"Accuracy Score:\")\n",
    "print(round(np.mean(acc), 4))\n",
    "print(\"----------------------------\")\n",
    "print(\"Features sorded by accuracy decrease:\")\n",
    "print(sorted([(round(np.mean(score), 4), feature) for feature, score in scores.items()], reverse=True))\n",
    "print(\"****************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:57: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by score:\n",
      "[(0.52500000000000002, 'worst concave points'), (0.48999999999999999, 'worst radius'), (0.435, 'mean concave points'), (0.33500000000000002, 'worst perimeter'), (0.26500000000000001, 'worst texture'), (0.20499999999999999, 'worst concavity'), (0.115, 'worst compactness'), (0.105, 'worst area'), (0.10000000000000001, 'mean perimeter'), (0.089999999999999997, 'mean concavity'), (0.074999999999999997, 'mean radius'), (0.059999999999999998, 'worst smoothness'), (0.040000000000000001, 'worst symmetry'), (0.025000000000000001, 'radius error'), (0.02, 'mean compactness'), (0.01, 'mean texture'), (0.01, 'mean area'), (0.0, 'worst fractal dimension'), (0.0, 'texture error'), (0.0, 'symmetry error'), (0.0, 'smoothness error'), (0.0, 'perimeter error'), (0.0, 'mean symmetry'), (0.0, 'mean smoothness'), (0.0, 'mean fractal dimension'), (0.0, 'fractal dimension error'), (0.0, 'concavity error'), (0.0, 'concave points error'), (0.0, 'compactness error'), (0.0, 'area error')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "\n",
    "bc = load_breast_cancer()\n",
    "X = bc[\"data\"]\n",
    "y = bc[\"target\"]\n",
    "names = bc[\"feature_names\"]\n",
    "\n",
    "rlasso = RandomizedLasso(alpha=0.005)\n",
    "rlasso.fit(X, y)\n",
    "\n",
    "print(\"Features sorted by score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rlasso.scores_), names), reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:57: DeprecationWarning: Class RandomizedLogisticRegression is deprecated; The class RandomizedLogisticRegression is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by score:\n",
      "[(0.55000000000000004, 'mean concave points'), (0.51500000000000001, 'worst radius'), (0.46500000000000002, 'worst texture'), (0.46500000000000002, 'worst concave points'), (0.44500000000000001, 'worst perimeter'), (0.315, 'mean texture'), (0.30499999999999999, 'worst concavity'), (0.27500000000000002, 'worst symmetry'), (0.25, 'worst smoothness'), (0.125, 'worst area'), (0.12, 'mean concavity'), (0.11, 'worst compactness'), (0.089999999999999997, 'mean perimeter'), (0.085000000000000006, 'mean radius'), (0.050000000000000003, 'mean smoothness'), (0.029999999999999999, 'radius error'), (0.014999999999999999, 'mean compactness'), (0.01, 'worst fractal dimension'), (0.01, 'mean area'), (0.0050000000000000001, 'perimeter error'), (0.0050000000000000001, 'area error'), (0.0, 'texture error'), (0.0, 'symmetry error'), (0.0, 'smoothness error'), (0.0, 'mean symmetry'), (0.0, 'mean fractal dimension'), (0.0, 'fractal dimension error'), (0.0, 'concavity error'), (0.0, 'concave points error'), (0.0, 'compactness error')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import RandomizedLogisticRegression\n",
    "\n",
    "bc = load_breast_cancer()\n",
    "X = bc[\"data\"]\n",
    "y = bc[\"target\"]\n",
    "names = bc[\"feature_names\"]\n",
    "\n",
    "rlr = RandomizedLogisticRegression()\n",
    "rlr.fit(X, y)\n",
    "\n",
    "print(\"Features sorted by score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rlr.scores_), names), reverse=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      " Features sorted by their rank:\n",
      "[(1, 'worst concavity'), (2, 'mean concavity'), (3, 'worst radius'), (4, 'mean radius'), (5, 'worst concave points'), (6, 'mean concave points'), (7, 'worst symmetry'), (8, 'mean symmetry'), (9, 'worst smoothness'), (10, 'worst fractal dimension'), (11, 'mean smoothness'), (12, 'mean perimeter'), (13, 'texture error'), (14, 'worst texture'), (15, 'mean texture'), (16, 'concavity error'), (17, 'area error'), (18, 'worst perimeter'), (19, 'mean compactness'), (20, 'symmetry error'), (21, 'worst compactness'), (22, 'concave points error'), (23, 'worst area'), (24, 'mean fractal dimension'), (25, 'smoothness error'), (26, 'radius error'), (27, 'perimeter error'), (28, 'compactness error'), (29, 'fractal dimension error'), (30, 'mean area')]\n",
      "\n",
      "Ridge \n",
      " Features sorted by their rank:\n",
      "[(1, 'worst concavity'), (2, 'worst concave points'), (3, 'mean concavity'), (4, 'mean concave points'), (5, 'worst compactness'), (6, 'worst symmetry'), (7, 'worst smoothness'), (8, 'mean symmetry'), (9, 'worst radius'), (10, 'radius error'), (11, 'mean compactness'), (12, 'mean smoothness'), (13, 'worst fractal dimension'), (14, 'concavity error'), (15, 'symmetry error'), (16, 'worst texture'), (17, 'concave points error'), (18, 'mean radius'), (19, 'compactness error'), (20, 'smoothness error'), (21, 'mean perimeter'), (22, 'mean fractal dimension'), (23, 'texture error'), (24, 'worst perimeter'), (25, 'mean texture'), (26, 'perimeter error'), (27, 'worst area'), (28, 'mean area'), (29, 'area error'), (30, 'fractal dimension error')]\n",
      "\n",
      "SVR \n",
      " Features sorted by theri rank:\n",
      "[(1, 'worst concave points'), (2, 'mean concave points'), (3, 'concavity error'), (4, 'compactness error'), (5, 'worst concavity'), (6, 'worst symmetry'), (7, 'mean compactness'), (8, 'radius error'), (9, 'mean symmetry'), (10, 'mean concavity'), (11, 'worst smoothness'), (12, 'mean smoothness'), (13, 'worst compactness'), (14, 'worst fractal dimension'), (15, 'symmetry error'), (16, 'perimeter error'), (17, 'smoothness error'), (18, 'worst radius'), (19, 'concave points error'), (20, 'worst texture'), (21, 'mean radius'), (22, 'worst perimeter'), (23, 'fractal dimension error'), (24, 'area error'), (25, 'texture error'), (26, 'mean perimeter'), (27, 'mean fractal dimension'), (28, 'mean texture'), (29, 'worst area'), (30, 'mean area')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "bc = load_breast_cancer()\n",
    "X = bc[\"data\"]\n",
    "y = bc[\"target\"]\n",
    "names = bc[\"feature_names\"]\n",
    "\n",
    "logir = LogisticRegression()\n",
    "rfe = RFE(logir, n_features_to_select=1)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "print(\"Logistic Regression\", \"\\n\", \"Features sorted by their rank:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names)))\n",
    "print()\n",
    "\n",
    "ridge = Ridge(alpha=7)\n",
    "rfe = RFE(ridge, n_features_to_select=1)\n",
    "rfe.fit(X, y)\n",
    "print(\"Ridge\", \"\\n\", \"Features sorted by their rank:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names)))\n",
    "print()\n",
    "\n",
    "svr = SVR(kernel=\"linear\")\n",
    "rfe = RFE(svr, n_features_to_select=1)\n",
    "rfe.fit(X, y)\n",
    "print(\"SVR\", \"\\n\", \"Features sorted by theri rank:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
